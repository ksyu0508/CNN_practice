{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pix2pix.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"nRHSHGLVjTvn","colab_type":"code","outputId":"d8cd6925-7eab-464f-8633-6c492e043f46","executionInfo":{"status":"ok","timestamp":1574151778888,"user_tz":-540,"elapsed":111335,"user":{"displayName":"김승유","photoUrl":"","userId":"10108524419038281793"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["from google.colab import auth\n","auth.authenticate_user()\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"847ddc59-cee9-4c35-c0dc-1d7414f28b61","executionInfo":{"status":"ok","timestamp":1574152069071,"user_tz":-540,"elapsed":1047,"user":{"displayName":"김승유","photoUrl":"","userId":"10108524419038281793"}},"id":"JdnINFvrw1ud","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import os\n","from pathlib import Path\n","###############자기 폴더 맞게#####################\n","folder = \"colab/\"\n","project_dir = \"pix2pix\"\n","\n","base_path = Path(\"/content/gdrive/My Drive/\")\n","project_path = base_path / folder / project_dir\n","os.chdir(project_path)\n","for x in list(project_path.glob(\"*\")):\n","    if x.is_dir():\n","        dir_name = str(x.relative_to(project_path))\n","        os.rename(dir_name, dir_name.split(\" \", 1)[0])\n","print(f\"현재 디렉토리 위치: {os.getcwd()}\")\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["현재 디렉토리 위치: /content/gdrive/My Drive/colab/pix2pix\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hqmy_FVH6w3C","colab_type":"code","outputId":"cb4d0429-36b7-4b38-e492-c09b69e70b6c","executionInfo":{"status":"ok","timestamp":1574151803762,"user_tz":-540,"elapsed":2579,"user":{"displayName":"김승유","photoUrl":"","userId":"10108524419038281793"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import numpy as np\n","%matplotlib inline\n","from torch.autograd import Variable\n","from itertools import chain\n","from PIL import Image\n","from torch.utils.data import DataLoader\n","\n","print('GPU 사용 가능 여부: {}'.format(torch.cuda.is_available()))\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["GPU 사용 가능 여부: True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FIIowgv48QWC","colab_type":"code","colab":{}},"source":["def to_variable(x):\n","    if torch.cuda.is_available():\n","        x = x.cuda()\n","    return Variable(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rg57sVDa8SRn","colab_type":"code","colab":{}},"source":["def denorm(x):\n","    out = (x + 1) / 2\n","    return out.clamp(0, 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lwptt6z38TkQ","colab_type":"code","colab":{}},"source":["def GAN_Loss(input, target, criterion):\n","    if target == True:\n","        tmp_tensor = torch.FloatTensor(input.size()).fill_(1.0)\n","        labels = Variable(tmp_tensor, requires_grad=False)\n","    else:\n","        tmp_tensor = torch.FloatTensor(input.size()).fill_(0.0)\n","        labels = Variable(tmp_tensor, requires_grad=False)\n","\n","    if torch.cuda.is_available():\n","        labels = labels.cuda()\n","\n","    return criterion(input, labels)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OKj-0WkA60zv","colab_type":"code","colab":{}},"source":["#하이퍼 파라미터\n","which_direction = 'AtoB' ### BtoA면 반대\n","\n","num_epochs = 100\n","batchSize = 1\n","lr = 0.0002\n","beta1 = 0.5 \n","beta2 = 0.999\n","lambda_A = 100.0\n","\n","sample_path = './result'\n","log_step = 10\n","sample_step = 100\n","num_workers = 2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lxl6uWkq_nUp","colab_type":"code","colab":{}},"source":["class ImageFolder(torch.utils.data.Dataset):\n","    def __init__(self):\n","        \n","        self.transformP = transforms.Compose([\n","                                             transforms.ToTensor(),\n","                                             transforms.Normalize((0.5, 0.5, 0.5),\n","                                                                  (0.5, 0.5, 0.5))])\n","        \n","        self.image_len = None\n","\n","        self.dir_base = './datasets' ###########데이터 위치\n","        \n","        self.rootA = os.path.join(self.dir_base, 'pikachu_black')   #### 데이터셋 1 폴더\n","        self.rootB = os.path.join(self.dir_base, 'pikachu_resized2') #### 데이터셋 2 폴더\n","        self.image_paths_A = list(map(lambda x: os.path.join(self.rootA, x), os.listdir(self.rootA)))\n","        self.image_paths_B = list(map(lambda x: os.path.join(self.rootB, x), os.listdir(self.rootB)))\n","        self.image_paths_A.sort()\n","        self.image_paths_B.sort()\n","        self.image_len = min(len(self.image_paths_A), len(self.image_paths_B))\n","\n","\n","    def __getitem__(self, index):\n","        A_path = self.image_paths_A[index]\n","        B_path = self.image_paths_B[index]\n","        A = Image.open(A_path).convert('RGB')\n","        B = Image.open(B_path).convert('RGB')\n","\n","        A = self.transformP(A)\n","        B = self.transformP(B)\n","\n","        return {'A': A, 'B': B}\n","\n","    def __len__(self):\n","        return self.image_len"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fcsJjfo69UR2","colab_type":"code","colab":{}},"source":["dataset = ImageFolder()\n","data_loader = DataLoader(dataset=dataset,\n","                          batch_size=batchSize,\n","                          shuffle=True,\n","                          num_workers=num_workers)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1cYOjUQXBFG8","colab_type":"code","colab":{}},"source":["######샘플 이미지 생성 경로\n","if not os.path.exists(sample_path):\n","    os.makedirs(sample_path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jtC4uZr-9WOu","colab_type":"code","colab":{}},"source":["#### 3x256x256 이미지 기준\n","\n","class Generator(nn.Module):\n","    def __init__(self, batch_size):\n","        super(Generator, self).__init__()\n","\n","        bn = None\n","        if batch_size == 1:\n","            bn = False # Instance Normalization\n","        else:\n","            bn = True # Batch Normalization\n","\n","        # [3x256x256] -> [64x128x128]\n","        self.conv1 = nn.Conv2d(3, 64, 4, 2, 1)\n","\n","        # -> [128x64x64]\n","        conv2 = [nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(64, 128, 4, 2, 1)]\n","        if bn == True:\n","            conv2 += [nn.BatchNorm2d(128)]\n","        else:\n","            conv2 += [nn.InstanceNorm2d(128)]\n","        self.conv2 = nn.Sequential(*conv2)\n","\n","        # -> [256x32x32]\n","        conv3 = [nn.LeakyReLU(0.2, inplace=True),\n","                 nn.Conv2d(128, 256, 4, 2, 1)]\n","        if bn == True:\n","            conv3 += [nn.BatchNorm2d(256)]\n","        else:\n","            conv3 += [nn.InstanceNorm2d(256)]\n","        self.conv3 = nn.Sequential(*conv3)\n","\n","        # -> [512x16x16]\n","        conv4 = [nn.LeakyReLU(0.2, inplace=True),\n","                 nn.Conv2d(256, 512, 4, 2, 1)]\n","        if bn == True:\n","            conv4 += [nn.BatchNorm2d(512)]\n","        else:\n","            conv4 += [nn.InstanceNorm2d(512)]\n","        self.conv4 = nn.Sequential(*conv4)\n","\n","        # -> [512x8x8]\n","        conv5 = [nn.LeakyReLU(0.2, inplace=True),\n","                 nn.Conv2d(512, 512, 4, 2, 1)]\n","        if bn == True:\n","            conv5 += [nn.BatchNorm2d(512)]\n","        else:\n","            conv5 += [nn.InstanceNorm2d(512)]\n","        self.conv5 = nn.Sequential(*conv5)\n","\n","        # -> [512x4x4]\n","        conv6 = [nn.LeakyReLU(0.2, inplace=True),\n","                 nn.Conv2d(512, 512, 4, 2, 1)]\n","        if bn == True:\n","            conv6 += [nn.BatchNorm2d(512)]\n","        else:\n","            conv6 += [nn.InstanceNorm2d(512)]\n","        self.conv6 = nn.Sequential(*conv6)\n","\n","        # -> [512x2x2]\n","        conv7 = [nn.LeakyReLU(0.2, inplace=True),\n","                 nn.Conv2d(512, 512, 4, 2, 1)]\n","        if bn == True:\n","            conv7 += [nn.BatchNorm2d(512)]\n","        else:\n","            conv7 += [nn.InstanceNorm2d(512)]\n","        self.conv7 = nn.Sequential(*conv7)\n","\n","        # -> [512x1x1]\n","        conv8 = [nn.LeakyReLU(0.2, inplace=True),\n","                 nn.Conv2d(512, 512, 4, 2, 1)]\n","        if bn == True:\n","            conv8 += [nn.BatchNorm2d(512)]\n","        else:\n","            conv8 += [nn.InstanceNorm2d(512)]\n","        self.conv8 = nn.Sequential(*conv8)\n","\n","        # -> [512x2x2]\n","        deconv8 = [nn.ReLU(),\n","                   nn.ConvTranspose2d(512, 512, 4, 2, 1)]\n","        if bn == True:\n","            deconv8 += [nn.BatchNorm2d(512), nn.Dropout(0.5)]\n","        else:\n","            deconv8 += [nn.InstanceNorm2d(512), nn.Dropout(0.5)]\n","        self.deconv8 = nn.Sequential(*deconv8)\n","\n","        # [(512+512)x2x2] -> [512x4x4]\n","        deconv7 = [nn.ReLU(),\n","                   nn.ConvTranspose2d(512 * 2, 512, 4, 2, 1)]\n","        if bn == True:\n","            deconv7 += [nn.BatchNorm2d(512), nn.Dropout(0.5)]\n","        else:\n","            deconv7 += [nn.InstanceNorm2d(512), nn.Dropout(0.5)]\n","        self.deconv7 = nn.Sequential(*deconv7)\n","\n","        # [(512+512)x4x4] -> [512x8x8]\n","        deconv6 = [nn.ReLU(),\n","                   nn.ConvTranspose2d(512 * 2, 512, 4, 2, 1)]\n","        if bn == True:\n","            deconv6 += [nn.BatchNorm2d(512), nn.Dropout(0.5)]\n","        else:\n","            deconv6 += [nn.InstanceNorm2d(512), nn.Dropout(0.5)]\n","        self.deconv6 = nn.Sequential(*deconv6)\n","\n","        # [(512+512)x8x8] -> [512x16x16]\n","        deconv5 = [nn.ReLU(),\n","                   nn.ConvTranspose2d(512 * 2, 512, 4, 2, 1)]\n","        if bn == True:\n","            deconv5 += [nn.BatchNorm2d(512)]\n","        else:\n","            deconv5 += [nn.InstanceNorm2d(512)]\n","        self.deconv5 = nn.Sequential(*deconv5)\n","\n","        # [(512+512)x16x16] -> [256x32x32]\n","        deconv4 = [nn.ReLU(),\n","                   nn.ConvTranspose2d(512 * 2, 256, 4, 2, 1)]\n","        if bn == True:\n","            deconv4 += [nn.BatchNorm2d(256)]\n","        else:\n","            deconv4 += [nn.InstanceNorm2d(256)]\n","        self.deconv4 = nn.Sequential(*deconv4)\n","\n","        # [(256+256)x32x32] -> [128x64x64]\n","        deconv3 = [nn.ReLU(),\n","                   nn.ConvTranspose2d(256 * 2, 128, 4, 2, 1)]\n","        if bn == True:\n","            deconv3 += [nn.BatchNorm2d(128)]\n","        else:\n","            deconv3 += [nn.InstanceNorm2d(128)]\n","        self.deconv3 = nn.Sequential(*deconv3)\n","\n","        # [(128+128)x64x64] -> [64x128x128]\n","        deconv2 = [nn.ReLU(),\n","                   nn.ConvTranspose2d(128 * 2, 64, 4, 2, 1)]\n","        if bn == True:\n","            deconv2 += [nn.BatchNorm2d(64)]\n","        else:\n","            deconv2 += [nn.InstanceNorm2d(64)]\n","        self.deconv2 = nn.Sequential(*deconv2)\n","\n","        # [(64+64)x128x128] -> [3x256x256]\n","        self.deconv1 = nn.Sequential(\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(64 * 2, 3, 4, 2, 1),\n","            nn.Tanh()\n","        )\n","\n","\n","    def forward(self, x):\n","\n","        c1 = self.conv1(x)\n","        c2 = self.conv2(c1)\n","        c3 = self.conv3(c2)\n","        c4 = self.conv4(c3)\n","        c5 = self.conv5(c4)\n","        c6 = self.conv6(c5)\n","        c7 = self.conv7(c6)\n","        c8 = self.conv8(c7)\n","\n","        d7 = self.deconv8(c8)\n","        d7 = torch.cat((c7, d7), dim=1)\n","        d6 = self.deconv7(d7)\n","        d6 = torch.cat((c6, d6), dim=1)\n","        d5 = self.deconv6(d6)\n","        d5 = torch.cat((c5, d5), dim=1)\n","        d4 = self.deconv5(d5)\n","        d4 = torch.cat((c4, d4), dim=1)\n","        d3 = self.deconv4(d4)\n","        d3 = torch.cat((c3, d3), dim=1)\n","        d2 = self.deconv3(d3)\n","        d2 = torch.cat((c2, d2), dim=1)\n","        d1 = self.deconv2(d2)\n","        d1 = torch.cat((c1, d1), dim=1)\n","        out = self.deconv1(d1)\n","\n","        return out\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, batch_size):\n","        super(Discriminator, self).__init__()\n","\n","        bn = None\n","        if batch_size == 1:\n","            bn = False  # Instance Normalization\n","        else:\n","            bn = True  # Batch Normalization\n","\n","        # [(3+3)x256x256] -> [64x128x128] -> [128x64x64]\n","        main = [nn.Conv2d(3*2, 64, 4, 2, 1),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(64, 128, 4, 2, 1)]\n","        if bn == True:\n","            main += [nn.BatchNorm2d(128)]\n","        else:\n","            main += [nn.InstanceNorm2d(128)]\n","\n","        # -> [256x32x32]\n","        main += [nn.LeakyReLU(0.2, inplace=True),\n","                  nn.Conv2d(128, 256, 4, 2, 1)]\n","        if bn == True:\n","            main += [nn.BatchNorm2d(256)]\n","        else:\n","            main += [nn.InstanceNorm2d(256)]\n","\n","        # -> [512x31x31] (Fully Convolutional)\n","        main += [nn.LeakyReLU(0.2, inplace=True),\n","                  nn.Conv2d(256, 512, 4, 1, 1)]\n","        if bn == True:\n","            main += [nn.BatchNorm2d(512)]\n","        else:\n","            main += [nn.InstanceNorm2d(512)]\n","\n","        # -> [1x30x30] (Fully Convolutional, PatchGAN)\n","        main += [nn.LeakyReLU(0.2, inplace=True),\n","                  nn.Conv2d(512, 1, 4, 1, 1),\n","                  nn.Sigmoid()]\n","\n","        self.main = nn.Sequential(*main)\n","\n","    def forward(self, x1, x2): # One for Real, One for Fake\n","        out = torch.cat((x1, x2), dim=1)\n","        return self.main(out)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pBmDNzoKA0Kr","colab_type":"code","colab":{}},"source":["generator = Generator(batchSize)\n","discriminator = Discriminator(batchSize)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jB2Ae-BYBQkT","colab_type":"code","colab":{}},"source":["criterionGAN = nn.BCELoss()\n","criterionL1 = nn.L1Loss()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oydZ7V_CBS7K","colab_type":"code","colab":{}},"source":["g_optimizer = torch.optim.Adam(generator.parameters(), lr, [beta1, beta2])\n","d_optimizer = torch.optim.Adam(discriminator.parameters(), lr, [beta1, beta2])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pFDqlmnoBWGw","colab_type":"code","colab":{}},"source":["if torch.cuda.is_available():\n","    generator = generator.cuda()\n","    discriminator = discriminator.cuda()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c-Fi9LhbBdLW","colab_type":"code","outputId":"1d238853-c5e7-4f02-e1ed-179aad865cf9","executionInfo":{"status":"error","timestamp":1574152294321,"user_tz":-540,"elapsed":184262,"user":{"displayName":"김승유","photoUrl":"","userId":"10108524419038281793"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["total_step = len(data_loader) # For Print Log\n","for epoch in range(num_epochs):\n","    for i, sample in enumerate(data_loader):\n","\n","        AtoB = which_direction == 'AtoB'\n","        input_A = sample['A' if AtoB else 'B']\n","        input_B = sample['B' if AtoB else 'A']\n","\n","        # ===================== Train D =====================#\n","        discriminator.zero_grad()\n","\n","        real_A = to_variable(input_A)\n","        fake_B = generator(real_A)\n","        real_B = to_variable(input_B)\n","\n","        # d_optimizer.zero_grad()\n","\n","        pred_fake = discriminator(real_A, fake_B)\n","        loss_D_fake = GAN_Loss(pred_fake, False, criterionGAN)\n","\n","        pred_real = discriminator(real_A, real_B)\n","        loss_D_real = GAN_Loss(pred_real, True, criterionGAN)\n","\n","        # Combined loss\n","        \n","        loss_D = (loss_D_fake + loss_D_real) * 0.5\n","        loss_D.backward(retain_graph=True)\n","        d_optimizer.step()\n","\n","        # ===================== Train G =====================#\n","        generator.zero_grad()\n","\n","        pred_fake = discriminator(real_A, fake_B)\n","        loss_G_GAN = GAN_Loss(pred_fake, True, criterionGAN)\n","\n","        loss_G_L1 = criterionL1(fake_B, real_B)\n","\n","        loss_G = loss_G_GAN + loss_G_L1 * lambda_A\n","        loss_G.backward()\n","        g_optimizer.step()\n","\n","        # print the log info\n","        if (i + 1) % log_step == 0:\n","            print('Epoch [%d/%d], BatchStep[%d/%d], D_Real_loss: %.4f, D_Fake_loss: %.4f, G_loss: %.4f, G_L1_loss: %.4f'\n","                  % (epoch + 1, num_epochs, i + 1, total_step, loss_D_real.item(), loss_D_fake.item(), loss_G_GAN.item(), loss_G_L1.item()))\n","\n","        # save the sampled images\n","        if (i + 1) % sample_step == 0:\n","            res = torch.cat((torch.cat((real_A, fake_B), dim=3), real_B), dim=3)\n","            torchvision.utils.save_image(denorm(res.data), os.path.join(sample_path, 'Generated-%d-%d.png' % (epoch + 1, i + 1)))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch [1/100], BatchStep[10/205], D_Real_loss: 0.7500, D_Fake_loss: 0.6889, G_loss: 0.7918, G_L1_loss: 0.3158\n","Epoch [1/100], BatchStep[20/205], D_Real_loss: 0.6260, D_Fake_loss: 0.5821, G_loss: 0.8608, G_L1_loss: 0.2734\n","Epoch [1/100], BatchStep[30/205], D_Real_loss: 0.8629, D_Fake_loss: 0.4334, G_loss: 1.0723, G_L1_loss: 0.1973\n","Epoch [1/100], BatchStep[40/205], D_Real_loss: 0.6485, D_Fake_loss: 0.3550, G_loss: 1.3381, G_L1_loss: 0.2284\n","Epoch [1/100], BatchStep[50/205], D_Real_loss: 0.4508, D_Fake_loss: 0.4288, G_loss: 1.5880, G_L1_loss: 0.1924\n","Epoch [1/100], BatchStep[60/205], D_Real_loss: 0.1942, D_Fake_loss: 0.3734, G_loss: 2.0410, G_L1_loss: 0.2030\n","Epoch [1/100], BatchStep[70/205], D_Real_loss: 0.4180, D_Fake_loss: 0.5548, G_loss: 1.6348, G_L1_loss: 0.1540\n","Epoch [1/100], BatchStep[80/205], D_Real_loss: 0.4121, D_Fake_loss: 0.6997, G_loss: 1.6360, G_L1_loss: 0.1227\n","Epoch [1/100], BatchStep[90/205], D_Real_loss: 0.5173, D_Fake_loss: 0.6596, G_loss: 0.9233, G_L1_loss: 0.0843\n","Epoch [1/100], BatchStep[100/205], D_Real_loss: 0.7764, D_Fake_loss: 0.3547, G_loss: 0.6532, G_L1_loss: 0.1370\n","Epoch [1/100], BatchStep[110/205], D_Real_loss: 0.5135, D_Fake_loss: 0.7358, G_loss: 1.2767, G_L1_loss: 0.0737\n","Epoch [1/100], BatchStep[120/205], D_Real_loss: 1.1947, D_Fake_loss: 0.2848, G_loss: 0.8286, G_L1_loss: 0.1067\n","Epoch [1/100], BatchStep[130/205], D_Real_loss: 0.7255, D_Fake_loss: 0.4052, G_loss: 0.3376, G_L1_loss: 0.0881\n","Epoch [1/100], BatchStep[140/205], D_Real_loss: 0.4841, D_Fake_loss: 0.5740, G_loss: 1.0169, G_L1_loss: 0.1068\n","Epoch [1/100], BatchStep[150/205], D_Real_loss: 0.6845, D_Fake_loss: 0.5564, G_loss: 0.8595, G_L1_loss: 0.2189\n","Epoch [1/100], BatchStep[160/205], D_Real_loss: 0.7367, D_Fake_loss: 0.5423, G_loss: 0.4139, G_L1_loss: 0.0864\n","Epoch [1/100], BatchStep[170/205], D_Real_loss: 0.5833, D_Fake_loss: 0.5033, G_loss: 1.1090, G_L1_loss: 0.3365\n","Epoch [1/100], BatchStep[180/205], D_Real_loss: 0.4944, D_Fake_loss: 0.4880, G_loss: 0.8713, G_L1_loss: 0.1083\n","Epoch [1/100], BatchStep[190/205], D_Real_loss: 0.4918, D_Fake_loss: 0.5136, G_loss: 1.0849, G_L1_loss: 0.1266\n","Epoch [1/100], BatchStep[200/205], D_Real_loss: 0.2157, D_Fake_loss: 0.7070, G_loss: 1.3775, G_L1_loss: 0.1516\n","Epoch [2/100], BatchStep[10/205], D_Real_loss: 0.3330, D_Fake_loss: 1.2185, G_loss: 1.0578, G_L1_loss: 0.0725\n","Epoch [2/100], BatchStep[20/205], D_Real_loss: 1.2548, D_Fake_loss: 0.3173, G_loss: 0.8405, G_L1_loss: 0.0930\n","Epoch [2/100], BatchStep[30/205], D_Real_loss: 0.6150, D_Fake_loss: 0.6544, G_loss: 0.7567, G_L1_loss: 0.1023\n","Epoch [2/100], BatchStep[40/205], D_Real_loss: 0.6563, D_Fake_loss: 0.6592, G_loss: 0.8381, G_L1_loss: 0.1169\n","Epoch [2/100], BatchStep[50/205], D_Real_loss: 0.1390, D_Fake_loss: 0.7892, G_loss: 0.8945, G_L1_loss: 0.1597\n","Epoch [2/100], BatchStep[60/205], D_Real_loss: 1.0175, D_Fake_loss: 0.6250, G_loss: 0.5027, G_L1_loss: 0.0766\n","Epoch [2/100], BatchStep[70/205], D_Real_loss: 0.4500, D_Fake_loss: 0.5657, G_loss: 1.0753, G_L1_loss: 0.0931\n","Epoch [2/100], BatchStep[80/205], D_Real_loss: 0.8712, D_Fake_loss: 0.3915, G_loss: 0.7298, G_L1_loss: 0.1142\n","Epoch [2/100], BatchStep[90/205], D_Real_loss: 1.0439, D_Fake_loss: 0.3927, G_loss: 0.6891, G_L1_loss: 0.0710\n","Epoch [2/100], BatchStep[100/205], D_Real_loss: 0.7181, D_Fake_loss: 0.3437, G_loss: 1.1334, G_L1_loss: 0.1251\n","Epoch [2/100], BatchStep[110/205], D_Real_loss: 0.4957, D_Fake_loss: 0.4830, G_loss: 0.9992, G_L1_loss: 0.2410\n","Epoch [2/100], BatchStep[120/205], D_Real_loss: 0.9298, D_Fake_loss: 0.3280, G_loss: 0.9102, G_L1_loss: 0.1082\n","Epoch [2/100], BatchStep[130/205], D_Real_loss: 0.1937, D_Fake_loss: 0.5798, G_loss: 1.4047, G_L1_loss: 0.1130\n","Epoch [2/100], BatchStep[140/205], D_Real_loss: 1.3013, D_Fake_loss: 1.1878, G_loss: 0.5718, G_L1_loss: 0.0939\n","Epoch [2/100], BatchStep[150/205], D_Real_loss: 0.8419, D_Fake_loss: 0.3337, G_loss: 0.8580, G_L1_loss: 0.1116\n","Epoch [2/100], BatchStep[160/205], D_Real_loss: 1.3583, D_Fake_loss: 0.3774, G_loss: 1.3226, G_L1_loss: 0.1469\n","Epoch [2/100], BatchStep[170/205], D_Real_loss: 0.2006, D_Fake_loss: 0.8164, G_loss: 1.3516, G_L1_loss: 0.1648\n","Epoch [2/100], BatchStep[180/205], D_Real_loss: 0.5628, D_Fake_loss: 0.1334, G_loss: 2.1987, G_L1_loss: 0.1529\n","Epoch [2/100], BatchStep[190/205], D_Real_loss: 0.3772, D_Fake_loss: 0.9118, G_loss: 1.4663, G_L1_loss: 0.0872\n","Epoch [2/100], BatchStep[200/205], D_Real_loss: 0.2130, D_Fake_loss: 0.3973, G_loss: 1.3512, G_L1_loss: 0.1473\n","Epoch [3/100], BatchStep[10/205], D_Real_loss: 0.2307, D_Fake_loss: 0.9964, G_loss: 1.2381, G_L1_loss: 0.1979\n","Epoch [3/100], BatchStep[20/205], D_Real_loss: 0.5720, D_Fake_loss: 0.4645, G_loss: 0.8506, G_L1_loss: 0.0962\n","Epoch [3/100], BatchStep[30/205], D_Real_loss: 0.7428, D_Fake_loss: 0.3079, G_loss: 1.2885, G_L1_loss: 0.1149\n","Epoch [3/100], BatchStep[40/205], D_Real_loss: 0.9147, D_Fake_loss: 0.1968, G_loss: 1.2888, G_L1_loss: 0.1159\n","Epoch [3/100], BatchStep[50/205], D_Real_loss: 0.9316, D_Fake_loss: 0.5105, G_loss: 0.6954, G_L1_loss: 0.0444\n","Epoch [3/100], BatchStep[60/205], D_Real_loss: 0.2596, D_Fake_loss: 0.2977, G_loss: 1.5954, G_L1_loss: 0.1569\n","Epoch [3/100], BatchStep[70/205], D_Real_loss: 0.9003, D_Fake_loss: 0.1632, G_loss: 1.1733, G_L1_loss: 0.1235\n","Epoch [3/100], BatchStep[80/205], D_Real_loss: 0.6804, D_Fake_loss: 0.2952, G_loss: 0.6040, G_L1_loss: 0.0909\n","Epoch [3/100], BatchStep[90/205], D_Real_loss: 0.7478, D_Fake_loss: 0.6763, G_loss: 0.9656, G_L1_loss: 0.0753\n","Epoch [3/100], BatchStep[100/205], D_Real_loss: 0.0474, D_Fake_loss: 0.6484, G_loss: 1.4060, G_L1_loss: 0.1213\n","Epoch [3/100], BatchStep[110/205], D_Real_loss: 0.0972, D_Fake_loss: 1.4217, G_loss: 1.2451, G_L1_loss: 0.1039\n","Epoch [3/100], BatchStep[120/205], D_Real_loss: 0.5698, D_Fake_loss: 0.4261, G_loss: 1.5060, G_L1_loss: 0.1494\n","Epoch [3/100], BatchStep[130/205], D_Real_loss: 0.5360, D_Fake_loss: 0.2832, G_loss: 1.6492, G_L1_loss: 0.1283\n","Epoch [3/100], BatchStep[140/205], D_Real_loss: 0.2108, D_Fake_loss: 0.1073, G_loss: 2.1548, G_L1_loss: 0.1321\n","Epoch [3/100], BatchStep[150/205], D_Real_loss: 2.5717, D_Fake_loss: 0.0820, G_loss: 1.3169, G_L1_loss: 0.0708\n","Epoch [3/100], BatchStep[160/205], D_Real_loss: 0.0488, D_Fake_loss: 1.2794, G_loss: 2.2562, G_L1_loss: 0.0984\n","Epoch [3/100], BatchStep[170/205], D_Real_loss: 0.9592, D_Fake_loss: 0.3428, G_loss: 0.5674, G_L1_loss: 0.0940\n","Epoch [3/100], BatchStep[180/205], D_Real_loss: 0.0655, D_Fake_loss: 0.4735, G_loss: 1.5026, G_L1_loss: 0.1096\n","Epoch [3/100], BatchStep[190/205], D_Real_loss: 0.3213, D_Fake_loss: 0.3518, G_loss: 1.2830, G_L1_loss: 0.1162\n","Epoch [3/100], BatchStep[200/205], D_Real_loss: 0.0340, D_Fake_loss: 0.3096, G_loss: 1.8091, G_L1_loss: 0.3873\n","Epoch [4/100], BatchStep[10/205], D_Real_loss: 1.0010, D_Fake_loss: 0.1999, G_loss: 1.1648, G_L1_loss: 0.0852\n","Epoch [4/100], BatchStep[20/205], D_Real_loss: 0.8265, D_Fake_loss: 1.2408, G_loss: 1.0154, G_L1_loss: 0.0875\n","Epoch [4/100], BatchStep[30/205], D_Real_loss: 0.6885, D_Fake_loss: 0.3687, G_loss: 1.1368, G_L1_loss: 0.2931\n","Epoch [4/100], BatchStep[40/205], D_Real_loss: 0.6386, D_Fake_loss: 0.4365, G_loss: 1.0991, G_L1_loss: 0.0846\n","Epoch [4/100], BatchStep[50/205], D_Real_loss: 0.6265, D_Fake_loss: 0.6358, G_loss: 1.1553, G_L1_loss: 0.0744\n","Epoch [4/100], BatchStep[60/205], D_Real_loss: 0.1834, D_Fake_loss: 0.4265, G_loss: 1.6302, G_L1_loss: 0.1303\n","Epoch [4/100], BatchStep[70/205], D_Real_loss: 1.5691, D_Fake_loss: 0.2174, G_loss: 0.9966, G_L1_loss: 0.0864\n","Epoch [4/100], BatchStep[80/205], D_Real_loss: 0.2354, D_Fake_loss: 1.8076, G_loss: 0.8845, G_L1_loss: 0.0598\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-bff3da26eb0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mreal_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mfake_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mreal_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-048ff81cebff>\u001b[0m in \u001b[0;36mto_variable\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mto_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"Go0b4-l6HiST","colab_type":"code","colab":{}},"source":["##############################test 데이터 출력##################################\n","def save_image(i):\n","      dir_base = './datasets'\n","      rootA = os.path.join(dir_base, 'pikachu_draw')\n","      image_paths_A = list(map(lambda x: os.path.join(rootA, x), os.listdir(rootA)))\n","      A_path = image_paths_A[1]\n","\n","      transform = transforms.Compose([\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize((0.5, 0.5, 0.5),\n","                                                            (0.5, 0.5, 0.5))])\n","      A = Image.open(A_path).convert('RGB')\n","      A = transform(A)\n","      real_A= to_variable(A)\n","      real_A = real_A.unsqueeze(0)\n","      fake_B= generator(real_A)\n","      res = torch.cat((torch.cat((real_A, fake_B), dim=3), real_A), dim=3)\n","      torchvision.utils.save_image(denorm(res.data), os.path.join(sample_path, 'Generated_draw_{}.png'.format(i))) \n","      print(\"Saved!\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6JgL0iVeYyYQ","colab_type":"code","outputId":"c0ce6e38-2ef5-4a37-f026-7a8c82ba99ab","executionInfo":{"status":"ok","timestamp":1574152332590,"user_tz":-540,"elapsed":2465,"user":{"displayName":"김승유","photoUrl":"","userId":"10108524419038281793"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["save_image(1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Saved!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7Kwl6VBAan_X","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}
